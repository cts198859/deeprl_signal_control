[MODEL_CONFIG]
rmsp_alpha = 0.99
rmsp_epsilon = 1e-5
max_grad_norm = 40
gamma = 0.95
lr_init = 5e-4
lr_decay = constant
entropy_coef_init = 0.2
entropy_coef_min = 0.02
entropy_decay = linear
entropy_ratio = 0.5
value_coef = 0.5
num_fc = 64
num_lstm = 64
num_h = 64
batch_size = 40
reward_norm = 50.0
reward_clip = 4.0

[TRAIN_CONFIG]
total_step = 1e5
test_interval = 1e4
log_interval = 10000

[ENV_CONFIG]
clip_wave = 2.0
clip_wait = 2.0
control_interval_sec = 5
; agent is greedy, iqll, iqld, ia2c, ma2c, a2c.
agent = ma2c
; coop discount is used to discount the neighbors' impact
coop_gamma = 0.75
data_path = ./large_grid/data/
episode_length_sec = 3600
; the normailization is based on typical values in sim
norm_wave = 3.0
norm_wait = 20.0
coef_wait = 0.5
num_ext_car_per_hour = 250
num_int_car_per_hour = 500
; objective is chosen from queue, wait, hybrid
objective = hybrid
scenario = large_grid
seed = 42
test_seeds = 10000,20000,30000
yellow_interval_sec = 2
